# -*- coding: utf-8 -*-
"""newbie

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vEuCn6h9Brhpj3PUVAI9l4KtYqeOrtUA
"""

from google.colab import drive
drive.mount('/content/drive')

import os

# Path to the dataset folder in Google Drive
dataset_base_path = '/content/drive/MyDrive/Dataset/1 1 BreakHis_Data-200x'

# Verify the path
if not os.path.exists(dataset_base_path):
    raise ValueError(f"Dataset path {dataset_base_path} does not exist.")

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Flatten
from tensorflow.keras.regularizers import l2

from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.preprocessing import image
import numpy as np
import seaborn as sns
from tensorflow.keras import layers

conv_base = ResNet50(
    weights='imagenet',
    include_top = False,
    input_shape=(150,150,3)
)

conv_base.summary()

for layer in conv_base.layers[-10:]:
    layer.trainable = True
model = keras.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)))
model.add(layers.Dropout(0.5))

model.add(layers.Dense(160, activation='relu', kernel_regularizer=l2(0.01)))
model.add(layers.Dropout(0.5))

model.add(layers.Dense(224, activation='relu', kernel_regularizer=l2(0.01)))
model.add(layers.Dropout(0.5))

model.add(layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)))
model.add(layers.Dropout(0.5))

model.add(layers.Dense(2, activation='softmax'))

model.summary()

model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# Define data augmentation for the training set
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2)
])

train_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/drive/MyDrive/Dataset/1 1 BreakHis_Data-200x/train',
    labels='inferred',
    label_mode = 'int',
    batch_size=32,
    image_size=(150,150)
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/drive/MyDrive/Dataset/1 1 BreakHis_Data-200x/val',
    labels='inferred',
    label_mode = 'int',
    batch_size=32,
    image_size=(150,150)
)

train_ds = train_ds.map(lambda x, y: (preprocess_input(x), y))
validation_ds = validation_ds.map(lambda x, y: (preprocess_input(x), y))

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

history = model.fit(train_ds, epochs=150, validation_data=validation_ds, callbacks=[early_stopping, reduce_lr])

import os # import the os module
# Define the directory to save the model
model_save_dir = '/content/drive/MyDrive/models/'
os.makedirs(model_save_dir, exist_ok=True)  # Create directory if it doesn't exist

# Save the trained model to the Google Drive directory
model_save_path = os.path.join(model_save_dir, 'trainedModel.h5')
model.save(model_save_path)

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'],color='red',label='train')
plt.plot(history.history['val_accuracy'],color='blue',label='validation')
plt.legend()
plt.show()
plt.plot(history.history['loss'],color='red',label='train')
plt.plot(history.history['val_loss'],color='blue',label='validation')
plt.legend()
plt.show()

# Evaluate the model on the validation set
val_labels = []
val_preds = []

for images, labels in validation_ds:
    preds = model.predict(images)
    val_labels.extend(labels.numpy())
    val_preds.extend(np.argmax(preds, axis=1))

# Generate confusion matrix
cm = confusion_matrix(val_labels, val_preds)
cm_labels = ['Benign', 'Malignant']  # Update with your actual class names if needed

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cm_labels, yticklabels=cm_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""Classification report"""

# Generate classification report
report = classification_report(val_labels, val_preds, target_names=cm_labels)
print(report)
TP = np.diag(cm)
FP = np.sum(cm, axis=0) - TP
FN = np.sum(cm, axis=1) - TP
TN = np.sum(cm) - (FP + FN + TP)

import pandas as pd
metrics_df = pd.DataFrame({
    'Class': cm_labels,
    'TP': TP,
    'TN': TN,
    'FP': FP,
    'FN': FN
})

print(metrics_df)

"""Testing model whether it give correct output or Not"""

model = keras.models.load_model('/content/drive/MyDrive/models/trainedModel.h5')
def preprocess_image(image_path):
    img = load_img(image_path, target_size=(150, 150))
    img = img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    return img


image_path = '/content/drive/MyDrive/Dataset/1 1 BreakHis_Data-200x/val/malignant/SOB_M_DC-14-11520-200-001.png'
image = preprocess_image(image_path)
# Predict the class
predictions = model.predict(image)
predicted_class = np.argmax(predictions, axis=1)[0]
print(f"Predicted Class: {predicted_class}")
if predicted_class == 0:
  print(f"Benign")
else:
  print(f"Malignant")

!pip install lime

"""Explainable AI - Lime"""

import tensorflow as tf
from tensorflow.keras.utils import load_img
from tensorflow.keras.utils import img_to_array  # Make sure to import img_to_array
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras import models
import numpy as np
# ... (rest of the code)

# Create a LIME explainer
explainer = lime_image.LimeImageExplainer()

# Define a prediction function for LIME
def predict_fn(images):
    images = np.array([preprocess_input(img_to_array(image)) for image in images]) #img_to_array should be accessible here as well.
    return model.predict(images)

# Generate LIME explanation
explanation = explainer.explain_instance(
    img_to_array(load_img(image_path, target_size=(150, 150))), # img_to_array call
    predict_fn,
    top_labels=4,
    num_samples=1000,
    batch_size=10
)


temp, mask = explanation.get_image_and_mask(
    explanation.top_labels[0],
    positive_only=True,
    num_features=10,
    hide_rest=True
)
img_boundry = mark_boundaries(temp / 255.0, mask)
plt.figure(figsize=(10, 5))

# Original image
plt.subplot(1, 2, 1)
plt.imshow(load_img(image_path, target_size=(150, 150)))
plt.title(f"True Class: {predicted_class}")

# LIME explanation
plt.subplot(1, 2, 2)
plt.imshow(img_boundry)
plt.title(f"Predicted Class: {predicted_class}")

plt.show()

"""// App Creation or inteface creation"""

import customtkinter as ctk
from tkinter import filedialog
from PIL import Image, ImageTk, ImageEnhance
import tensorflow as tf
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.applications.resnet50 import preprocess_input
import numpy as np
import threading

model = tf.keras.models.load_model('/python_work/models/BCD/resnet50htpp.h5')

ctk.set_appearance_mode("dark")
ctk.set_default_color_theme("blue")

def prepare_image(image_path):
    img = load_img(image_path, target_size=(150, 150))
    img = img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    return img

def show_loading_spinner():
    result_label.configure(text="Analyzing...", text_color="yellow")
    spinner.start()

def hide_loading_spinner():
    spinner.stop()

def predict_image():
    file_path = filedialog.askopenfilename()
    if not file_path:
        return

    show_loading_spinner()

    # Run prediction in a separate thread to avoid freezing UI
    threading.Thread(target=lambda: predict_and_display(file_path)).start()

def predict_and_display(file_path):
    image = prepare_image(file_path)
    predictions = model.predict(image)
    pred_class = np.argmax(predictions, axis=1)
    label_text = "Benign" if pred_class[0] == 0 else "Malignant"
    color = "green" if pred_class[0] == 0 else "red"


    result_label.configure(text=f"Prediction: {label_text}", text_color=color)
    hide_loading_spinner()

    img = Image.open(file_path).resize((150, 150))
    img = ImageEnhance.Color(img).enhance(1.5)
    img = ImageTk.PhotoImage(img)
    image_label.configure(image=img, text="")
    image_label.image = img

    card_frame.configure(border_color=color)

app = ctk.CTk()
app.title("Breast Cancer Image Classifier")
app.geometry("600x800")

app.configure(bg="#2c3e50")

title_label = ctk.CTkLabel(app, text="Breast Cancer Classifier", font=("Arial", 26, "bold"), text_color="cyan")
title_label.pack(pady=20)

description_label = ctk.CTkLabel(app, text="Select an image to determine if it's Benign or Malignant", font=("Arial", 16, "italic"), text_color="lightgray")
description_label.pack(pady=5)

card_frame = ctk.CTkFrame(app, width=400, height=400, corner_radius=15, fg_color="grey20", border_width=5)
card_frame.pack(pady=30)
card_frame.pack_propagate(False)

image_label = ctk.CTkLabel(card_frame, text="Selected Image Will Appear Here", font=("Helvetica", 14, "italic"), fg_color="grey30", text_color="white", width=200, height=200, corner_radius=10)
image_label.pack(pady=20)

result_label = ctk.CTkLabel(card_frame, text="", font=("Helvetica", 18, "bold"), text_color="cyan")
result_label.pack(pady=10)

upload_button = ctk.CTkButton(app, text="Select Image", command=predict_image, width=200, corner_radius=10, fg_color="#2980b9", text_color="white", hover_color="#3498db")
upload_button.pack(pady=20)

spinner = ctk.CTkProgressBar(app, orientation="horizontal", mode="indeterminate", width=200)
spinner.configure(progress_color="#ff6f61")
spinner.pack(pady=10)

app.mainloop()